{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GNN for fraud detection:\n",
    "Creating a multigraph for fraud detection using transaction data and applying a Graph Neural Network (GNN) on the edge list can be done in the following steps:\n",
    "\n",
    "1. Prepare the transaction data: Collect and organize the transaction data into a format that can be used to create the edges of the multigraph. For example, each transaction could be represented as a tuple (node1, node2, attributes), where node1 and node2 represent the sender and receiver of the transaction, and attributes is a dictionary containing properties such as the amount, timestamp, and transaction type.\n",
    "\n",
    "2. Create the multigraph: Use the transaction data to create a multigraph using the NetworkX library. The add_edge() method can be used to add edges to the multigraph, where each edge represents a transaction.\n",
    "\n",
    "3. Extract the edges list and their features: Use the edges() method of the multigraph to extract the edges list and their features, which will be used as input to the GNN.\n",
    "\n",
    "4. Apply a GNN on the edge list: Use a GNN library such as PyTorch Geometric, Deep Graph Library (DGL) or Spektral to apply a GNN on the edge list. The GNN will learn representations of the edges in the multigraph and use them to classify the edges as fraudulent or non-fraudulent.\n",
    "\n",
    "5. Evaluation: To evaluate the performance of the GNN, you can split the data into train and test sets, and use the test set to evaluate the accuracy, precision, recall, and F1-score of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph construction \n",
    "\n",
    "When constructing a graph with transaction edges between card_id and merchant_name, the first step is to identify the nodes in the graph. In this case, the card_id and merchant_name represent the nodes in the graph. Each card_id represents a unique credit card and each merchant_name represents a unique merchant. These nodes can be created by extracting the card_id and merchant_name information from the tabular data and storing them in separate lists.\n",
    "\n",
    "Once the nodes have been identified, the next step is to create edges between them. These edges represent the transactions that have taken place between a card_id and a merchant_name. To create the edges, a list of transactions is created and for each transaction, an edge is created between the card_id and merchant_name.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are creating an empty multigraph object called G using the nx.MultiGraph() function from the NetworkX library. Then we add nodes to the graph for each unique card_id and merchant_name from the dataframe df.\n",
    "\n",
    "The add_nodes_from method is used to add nodes to the graph, it takes an iterable as input and creates a node for each element in the iterable. The df[\"card_id\"].unique() will return a list of unique card_ids in the dataframe, and the df[\"Merchant Name\"].unique will return a list of all the merchant names in the dataframe.\n",
    "\n",
    "The type attribute is added to each node, it is used to differentiate between card_id and merchant_name nodes. This will help later on when we want to analyze the graph.\n",
    "\n",
    "**Why did we use a multigraph and not graph?**\n",
    "\n",
    "The same user (card_id) can buy from the same merchant (Merchant Name) multiple times, so we can have multiple edges between the user and the merchant and for this reason we used multigraph instead of graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Final-Year-Project\\\\Credit-Card-Fraud-Detection-Using-GNN'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"artifacts/data_transformation/transformed_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1296675 entries, 0 to 1296674\n",
      "Data columns (total 18 columns):\n",
      " #   Column                        Non-Null Count    Dtype  \n",
      "---  ------                        --------------    -----  \n",
      " 0   high_amt                      1296675 non-null  float64\n",
      " 1   amt_ratio_merchant            1296675 non-null  float64\n",
      " 2   sqrt_amt                      1296675 non-null  float64\n",
      " 3   amt                           1296675 non-null  float64\n",
      " 4   customer_avg_amt              1296675 non-null  float64\n",
      " 5   amt_diff_customer_avg         1296675 non-null  float64\n",
      " 6   hour_cos                      1296675 non-null  float64\n",
      " 7   amt_per_city_pop              1296675 non-null  float64\n",
      " 8   customer_min_amt              1296675 non-null  float64\n",
      " 9   merchant_category_fraud_risk  1296675 non-null  float64\n",
      " 10  merchant_avg_amt              1296675 non-null  float64\n",
      " 11  merchant_min_amt              1296675 non-null  float64\n",
      " 12  customer_amt_std              1296675 non-null  float64\n",
      " 13  merchant_amt_std              1296675 non-null  float64\n",
      " 14  customer_id                   1296675 non-null  int64  \n",
      " 15  merchant_id                   1296675 non-null  int64  \n",
      " 16  transaction_unique            1296675 non-null  int64  \n",
      " 17  is_fraud                      1296675 non-null  int64  \n",
      "dtypes: float64(14), int64(4)\n",
      "memory usage: 178.1 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entity\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class GraphConstructionConfig:\n",
    "    root_dir: Path\n",
    "    transformed_data_path: Path\n",
    "    graph_data_path: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Credit_Card_Fraud_Detection.constants import *\n",
    "from Credit_Card_Fraud_Detection.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath=CONFIG_FILE_PATH,\n",
    "        params_filepath=PARAMS_FILE_PATH,\n",
    "        schema_filepath=SCHEMA_FILE_PATH\n",
    "    ):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_graph_construction_config(self) -> GraphConstructionConfig:\n",
    "        print(\"get_graph_construction_config method called\") # add this line\n",
    "        config = self.config.graph_construction\n",
    "        create_directories([config.root_dir])\n",
    "        \n",
    "        graph_construction_config = GraphConstructionConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            transformed_data_path=config.transformed_data_path,\n",
    "            graph_data_path=config.graph_data_path,\n",
    "        )\n",
    "        return graph_construction_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import torch\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from Credit_Card_Fraud_Detection import logger\n",
    "# from torch_geometric.data import Data \n",
    "# from torch_geometric.data import HeteroData\n",
    "# from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import torch\n",
    "# from torch_geometric.data import HeteroData\n",
    "# import logging\n",
    "# import os\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Configure logging\n",
    "# logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "# logger = logging.getLogger(__name__)\n",
    "\n",
    "# class GraphConstructor:\n",
    "#     def __init__(self, config):\n",
    "#         self.config = config\n",
    "\n",
    "#     def create_node_ids(self, df):\n",
    "#         card_ids = {num: i for i, num in enumerate(df[\"card_id\"].unique())}\n",
    "#         merchant_ids = {name: i for i, name in enumerate(df[\"merchant\"].unique())}\n",
    "#         transaction_ids = {t: i for i, t in enumerate(df[\"transaction_unique\"].unique())}\n",
    "\n",
    "#         df[\"transaction_node\"] = df[\"transaction_unique\"].map(transaction_ids).astype(int)\n",
    "#         df[\"card_node\"] = df[\"card_id\"].map(card_ids).astype(int)\n",
    "#         df[\"merchant_node\"] = df[\"merchant\"].map(merchant_ids).astype(int)\n",
    "\n",
    "#         logger.info(f\"New max transaction_node in df: {df['transaction_node'].max()}\")\n",
    "#         logger.info(f\"Total transaction nodes after remapping: {len(transaction_ids)}\")\n",
    "#         logger.info(\"Node indices created successfully.\")\n",
    "\n",
    "#         return df, len(card_ids), len(merchant_ids), len(transaction_ids)\n",
    "\n",
    "#     def create_edge_indices(self, df):\n",
    "#         card_to_transaction_edges = torch.tensor(df[[\"card_node\", \"transaction_node\"]].values.T, dtype=torch.long)\n",
    "#         transaction_to_merchant_edges = torch.tensor(df[[\"transaction_node\", \"merchant_node\"]].values.T, dtype=torch.long)\n",
    "\n",
    "#         logger.info(f\"Card-to-Transaction edges shape: {card_to_transaction_edges.shape}\")\n",
    "#         logger.info(f\"Transaction-to-Merchant edges shape: {transaction_to_merchant_edges.shape}\")\n",
    "\n",
    "#         return card_to_transaction_edges, transaction_to_merchant_edges\n",
    "\n",
    "#     def create_node_features(self, df, num_card_nodes, num_merchant_nodes, num_transaction_nodes):\n",
    "#         numerical_features = [\"amt\", \"city_pop\", \"lat\", \"long\", \"merch_lat\", \"merch_long\", \"age\"] # Hardcoded list\n",
    "\n",
    "#         node_features_dim = len(numerical_features)\n",
    "\n",
    "#         card_features = torch.zeros((num_card_nodes, node_features_dim), dtype=torch.float32)\n",
    "#         merchant_features = torch.zeros((num_merchant_nodes, node_features_dim), dtype=torch.float32)\n",
    "\n",
    "#         for card_id, group in df.groupby(\"card_node\"):\n",
    "#             if card_id < num_card_nodes:\n",
    "#                 card_features[card_id] = torch.tensor(group[numerical_features].mean().values, dtype=torch.float32)\n",
    "\n",
    "#         for merchant_id, group in df.groupby(\"merchant_node\"):\n",
    "#             if merchant_id < num_merchant_nodes:\n",
    "#                 merchant_features[merchant_id] = torch.tensor(group[numerical_features].mean().values, dtype=torch.float32)\n",
    "\n",
    "#         transaction_features = torch.tensor(df[numerical_features].values, dtype=torch.float32)\n",
    "\n",
    "#         logger.info(\"Node features created correctly.\")\n",
    "\n",
    "#         return card_features, merchant_features, transaction_features\n",
    "\n",
    "#     def create_transaction_labels(self, df):\n",
    "#         y = torch.tensor(df[\"is_fraud\"].values, dtype=torch.float32).view(-1, 1)\n",
    "#         return y\n",
    "\n",
    "#     def train_test_split_nodes(self, y, num_transaction_nodes, test_size=0.2, random_state=42):\n",
    "#         train_mask, test_mask = train_test_split(\n",
    "#             torch.arange(num_transaction_nodes),\n",
    "#             test_size=test_size,\n",
    "#             random_state=random_state,\n",
    "#             stratify=y.squeeze().numpy()\n",
    "#         )\n",
    "\n",
    "#         transaction_train_mask = torch.zeros(num_transaction_nodes, dtype=torch.bool)\n",
    "#         transaction_test_mask = torch.zeros(num_transaction_nodes, dtype=torch.bool)\n",
    "#         transaction_train_mask[train_mask] = True\n",
    "#         transaction_test_mask[test_mask] = True\n",
    "\n",
    "#         logger.info(\"Train-test split applied.\")\n",
    "\n",
    "#         return transaction_train_mask, transaction_test_mask\n",
    "\n",
    "#     def describe_data_structure(self, data, filepath):\n",
    "#         with open(filepath, 'w') as f:\n",
    "#             f.write(\"Data Object Structure:\\n\")\n",
    "#             for node_type in data.node_types:\n",
    "#                 f.write(f\"  Node type: {node_type}\\n\")\n",
    "#                 if hasattr(data[node_type], 'x'):\n",
    "#                     f.write(f\"    x: {data[node_type].x.shape}, dtype={data[node_type].x.dtype}\\n\")\n",
    "#                 if hasattr(data[node_type], 'y'):\n",
    "#                     f.write(f\"    y: {data[node_type].y.shape}, dtype={data[node_type].y.dtype}\\n\")\n",
    "#                 if hasattr(data[node_type], 'train_mask'):\n",
    "#                     f.write(f\"    train_mask: {data[node_type].train_mask.shape}, dtype={data[node_type].train_mask.dtype}\\n\")\n",
    "#                 if hasattr(data[node_type], 'test_mask'):\n",
    "#                     f.write(f\"    test_mask: {data[node_type].test_mask.shape}, dtype={data[node_type].test_mask.dtype}\\n\")\n",
    "#             for edge_type in data.edge_types:\n",
    "#                 f.write(f\"  Edge type: {edge_type}\\n\")\n",
    "#                 f.write(f\"    edge_index: {data[edge_type].edge_index.shape}, dtype={data[edge_type].edge_index.dtype}\\n\")\n",
    "\n",
    "#         logger.info(f\"Data structure description saved to: {filepath}\")\n",
    "\n",
    "#     def construct_graph(self):\n",
    "#         df = pd.read_csv(self.config.transformed_data_path)\n",
    "\n",
    "#         df, num_card_nodes, num_merchant_nodes, num_transaction_nodes = self.create_node_ids(df)\n",
    "#         card_to_transaction_edges, transaction_to_merchant_edges = self.create_edge_indices(df)\n",
    "#         card_features, merchant_features, transaction_features = self.create_node_features(df, num_card_nodes, num_merchant_nodes, num_transaction_nodes)\n",
    "#         y = self.create_transaction_labels(df)\n",
    "#         transaction_train_mask, transaction_test_mask = self.train_test_split_nodes(y, num_transaction_nodes)\n",
    "\n",
    "#         data = HeteroData()\n",
    "#         data[\"card\"].x = card_features\n",
    "#         data[\"merchant\"].x = merchant_features\n",
    "#         data[\"transaction\"].x = transaction_features\n",
    "#         data[\"card\", \"transacts\", \"transaction\"].edge_index = card_to_transaction_edges\n",
    "#         data[\"transaction\", \"occurs_at\", \"merchant\"].edge_index = transaction_to_merchant_edges\n",
    "#         data[\"transaction\", \"transacted_by\", \"card\"].edge_index = card_to_transaction_edges.flip(0)\n",
    "#         data[\"merchant\", \"related_to\", \"transaction\"].edge_index = transaction_to_merchant_edges.flip(0)\n",
    "#         data[\"transaction\"].y = y\n",
    "#         data[\"transaction\"].train_mask = transaction_train_mask\n",
    "#         data[\"transaction\"].test_mask = transaction_test_mask\n",
    "\n",
    "#         torch.save(data, self.config.graph_data_path)\n",
    "#         logger.info(f\"Graph data saved to: {self.config.graph_data_path}\")\n",
    "\n",
    "#         # Save graph structure description\n",
    "#         structure_save_path = os.path.join(self.config.root_dir, \"graph_structure.txt\")\n",
    "#         self.describe_data_structure(data, structure_save_path)\n",
    "\n",
    "#         # Save updated DataFrame\n",
    "#         node_mapped_data_path = os.path.join(self.config.root_dir, \"node_mapped_data.csv\")\n",
    "#         df.to_csv(node_mapped_data_path, index=False)\n",
    "#         logger.info(f\"Updated data frame saved to: {node_mapped_data_path}\")\n",
    "\n",
    "#         return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "import logging\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class GraphConstructor:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "\n",
    "    def create_node_ids(self, df):\n",
    "        customer_ids = {num: i for i, num in enumerate(df[\"customer_id\"].unique())}\n",
    "        merchant_ids = {num: i for i, num in enumerate(df[\"merchant_id\"].unique())}\n",
    "        transaction_ids = {t: i for i, t in enumerate(df[\"transaction_unique\"].unique())}\n",
    "\n",
    "        df[\"transaction_node\"] = df[\"transaction_unique\"].map(transaction_ids).astype(int)\n",
    "        df[\"customer_node\"] = df[\"customer_id\"].map(customer_ids).astype(int)\n",
    "        df[\"merchant_node\"] = df[\"merchant_id\"].map(merchant_ids).astype(int)\n",
    "\n",
    "        logger.info(f\"New max transaction_node in df: {df['transaction_node'].max()}\")\n",
    "        logger.info(f\"Total transaction nodes after remapping: {len(transaction_ids)}\")\n",
    "        logger.info(\"Node indices created successfully.\")\n",
    "\n",
    "        return df, customer_ids, merchant_ids, transaction_ids\n",
    "\n",
    "    def create_edge_indices(self, df):\n",
    "        customer_to_transaction_edges = torch.tensor(df[[\"customer_node\", \"transaction_node\"]].values.T, dtype=torch.long)\n",
    "        transaction_to_merchant_edges = torch.tensor(df[[\"transaction_node\", \"merchant_node\"]].values.T, dtype=torch.long)\n",
    "\n",
    "        logger.info(f\"Customer-to-Transaction edges shape: {customer_to_transaction_edges.shape}\")\n",
    "        logger.info(f\"Transaction-to-Merchant edges shape: {transaction_to_merchant_edges.shape}\")\n",
    "\n",
    "        return customer_to_transaction_edges, transaction_to_merchant_edges\n",
    "\n",
    "    def create_node_features(self, df, customer_ids, merchant_ids, transaction_ids):\n",
    "        customer_features_list = [\"customer_avg_amt\", \"customer_min_amt\", \"customer_amt_std\"]\n",
    "        merchant_features_list = [\"merchant_avg_amt\", \"merchant_min_amt\", \"merchant_amt_std\"]\n",
    "        transaction_features_list = [\n",
    "            \"high_amt\", \"amt_ratio_merchant\", \"sqrt_amt\", \"amt\", \"amt_diff_customer_avg\",\n",
    "            \"hour_cos\", \"amt_per_city_pop\", \"merchant_category_fraud_risk\"\n",
    "        ]\n",
    "\n",
    "        customer_features_dim = len(customer_features_list)\n",
    "        merchant_features_dim = len(merchant_features_list)\n",
    "        transaction_features_dim = len(transaction_features_list)\n",
    "\n",
    "        customer_features = torch.zeros((len(customer_ids), customer_features_dim), dtype=torch.float32)\n",
    "        merchant_features = torch.zeros((len(merchant_ids), merchant_features_dim), dtype=torch.float32)\n",
    "        transaction_features = torch.tensor(df[transaction_features_list].values, dtype=torch.float32)\n",
    "\n",
    "        for customer_id, group in df.groupby(\"customer_node\"):\n",
    "            if customer_id < len(customer_ids):\n",
    "                customer_features[customer_id] = torch.tensor(group[customer_features_list].mean().values, dtype=torch.float32)\n",
    "\n",
    "        for merchant_id, group in df.groupby(\"merchant_node\"):\n",
    "            if merchant_id < len(merchant_ids):\n",
    "                merchant_features[merchant_id] = torch.tensor(group[merchant_features_list].mean().values, dtype=torch.float32)\n",
    "\n",
    "        logger.info(\"Node features created correctly.\")\n",
    "\n",
    "        return customer_features, merchant_features, transaction_features\n",
    "\n",
    "    def create_transaction_labels(self, df, transaction_ids):\n",
    "        \"\"\"Creates labels only for unique transaction nodes.\"\"\"\n",
    "        transaction_labels = {}\n",
    "        for transaction_id, group in df.groupby(\"transaction_unique\"):\n",
    "            transaction_labels[transaction_id] = group[\"is_fraud\"].iloc[0]\n",
    "\n",
    "        y = torch.tensor([transaction_labels[transaction_id] for transaction_id in transaction_ids.keys()], dtype=torch.float32).view(-1, 1)\n",
    "        return y\n",
    "\n",
    "    def train_test_split_nodes(self, y, num_transaction_nodes, test_size=0.2, random_state=42):\n",
    "        train_indices, test_indices = train_test_split(\n",
    "            torch.arange(num_transaction_nodes),\n",
    "            test_size=test_size,\n",
    "            random_state=random_state,\n",
    "            stratify=y.squeeze().numpy()\n",
    "        )\n",
    "\n",
    "        transaction_train_mask = torch.zeros(num_transaction_nodes, dtype=torch.bool)\n",
    "        transaction_test_mask = torch.zeros(num_transaction_nodes, dtype=torch.bool)\n",
    "\n",
    "        transaction_train_mask[train_indices] = True\n",
    "        transaction_test_mask[test_indices] = True\n",
    "\n",
    "        logger.info(\"Train-test split applied.\")\n",
    "\n",
    "        return transaction_train_mask, transaction_test_mask\n",
    "\n",
    "    def describe_data_structure(self, data, filepath):\n",
    "        with open(filepath, 'w') as f:\n",
    "            f.write(\"Data Object Structure:\\n\")\n",
    "            for node_type in data.node_types:\n",
    "                f.write(f\"  Node type: {node_type}\\n\")\n",
    "                if hasattr(data[node_type], 'x'):\n",
    "                    f.write(f\"    x: {data[node_type].x.shape}, dtype={data[node_type].x.dtype}\\n\")\n",
    "                if hasattr(data[node_type], 'y'):\n",
    "                    f.write(f\"    y: {data[node_type].y.shape}, dtype={data[node_type].y.dtype}\\n\")\n",
    "                if hasattr(data[node_type], 'train_mask'):\n",
    "                    f.write(f\"    train_mask: {data[node_type].train_mask.shape}, dtype={data[node_type].train_mask.dtype}\\n\")\n",
    "                if hasattr(data[node_type], 'test_mask'):\n",
    "                    f.write(f\"    test_mask: {data[node_type].test_mask.shape}, dtype={data[node_type].test_mask.dtype}\\n\")\n",
    "                if hasattr(data[node_type], 'n_id'):\n",
    "                    f.write(f\"    n_id: {data[node_type].n_id.shape}, dtype={data[node_type].n_id.dtype}\\n\")\n",
    "            for edge_type in data.edge_types:\n",
    "                f.write(f\"  Edge type: {edge_type}\\n\")\n",
    "                f.write(f\"    edge_index: {data[edge_type].edge_index.shape}, dtype={data[edge_type].edge_index.dtype}\\n\")\n",
    "\n",
    "        logger.info(f\"Data structure description saved to: {filepath}\")\n",
    "\n",
    "    def construct_graph(self):\n",
    "        df = pd.read_csv(self.config.transformed_data_path)\n",
    "\n",
    "        df, customer_ids, merchant_ids, transaction_ids = self.create_node_ids(df)\n",
    "        customer_to_transaction_edges, transaction_to_merchant_edges = self.create_edge_indices(df)\n",
    "        customer_features, merchant_features, transaction_features = self.create_node_features(df, customer_ids, merchant_ids, transaction_ids)\n",
    "        y = self.create_transaction_labels(df, transaction_ids)\n",
    "        transaction_train_mask, transaction_test_mask = self.train_test_split_nodes(y, len(transaction_ids))\n",
    "\n",
    "        data = HeteroData()\n",
    "        data[\"customer\"].x = customer_features\n",
    "        data[\"merchant\"].x = merchant_features\n",
    "        data[\"transaction\"].x = transaction_features\n",
    "        data[\"customer\", \"transacts\", \"transaction\"].edge_index = customer_to_transaction_edges\n",
    "        data[\"transaction\", \"occurs_at\", \"merchant\"].edge_index = transaction_to_merchant_edges\n",
    "        data[\"transaction\", \"transacted_by\", \"customer\"].edge_index = customer_to_transaction_edges.flip(0)\n",
    "        data[\"merchant\", \"related_to\", \"transaction\"].edge_index = transaction_to_merchant_edges.flip(0)\n",
    "        data[\"transaction\"].y = y\n",
    "        data[\"transaction\"].train_mask = transaction_train_mask\n",
    "        data[\"transaction\"].test_mask = transaction_test_mask\n",
    "\n",
    "        # Assign n_id attributes\n",
    "        data[\"customer\"].n_id = torch.tensor(list(customer_ids.keys()))\n",
    "        data[\"merchant\"].n_id = torch.tensor(list(merchant_ids.values()))\n",
    "        data[\"transaction\"].n_id = torch.tensor(list(transaction_ids.keys()))\n",
    "\n",
    "        torch.save(data, self.config.graph_data_path)\n",
    "        logger.info(f\"Graph data saved to: {self.config.graph_data_path}\")\n",
    "\n",
    "        # Save graph structure description\n",
    "        structure_save_path = os.path.join(self.config.root_dir, \"graph_structure.txt\")\n",
    "        self.describe_data_structure(data, structure_save_path)\n",
    "\n",
    "        # Save updated DataFrame\n",
    "        node_mapped_data_path = os.path.join(self.config.root_dir, \"node_mapped_data.csv\")\n",
    "        df.to_csv(node_mapped_data_path, index=False)\n",
    "        logger.info(f\"Updated data frame saved to: {node_mapped_data_path}\")\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-03-22 22:05:00,625: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-03-22 22:05:00,625: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-03-22 22:05:00,625: INFO: common: yaml file: schema.yaml loaded successfully]\n",
      "[2025-03-22 22:05:00,625: INFO: common: created directory at: artifacts]\n",
      "get_graph_construction_config method called\n",
      "[2025-03-22 22:05:00,625: INFO: common: created directory at: artifacts/graph_construction]\n",
      "[2025-03-22 22:05:02,762: INFO: 1079044015: New max transaction_node in df: 1296674]\n",
      "[2025-03-22 22:05:02,762: INFO: 1079044015: Total transaction nodes after remapping: 1296675]\n",
      "[2025-03-22 22:05:02,762: INFO: 1079044015: Node indices created successfully.]\n",
      "[2025-03-22 22:05:02,795: INFO: 1079044015: Customer-to-Transaction edges shape: torch.Size([2, 1296675])]\n",
      "[2025-03-22 22:05:02,795: INFO: 1079044015: Transaction-to-Merchant edges shape: torch.Size([2, 1296675])]\n",
      "[2025-03-22 22:05:04,056: INFO: 1079044015: Node features created correctly.]\n",
      "[2025-03-22 22:05:43,084: INFO: 1079044015: Train-test split applied.]\n",
      "[2025-03-22 22:05:43,500: INFO: 1079044015: Graph data saved to: artifacts/graph_construction/graph_data.pt]\n",
      "[2025-03-22 22:05:43,500: INFO: 1079044015: Data structure description saved to: artifacts/graph_construction\\graph_structure.txt]\n",
      "[2025-03-22 22:05:54,297: INFO: 1079044015: Updated data frame saved to: artifacts/graph_construction\\node_mapped_data.csv]\n",
      "[2025-03-22 22:05:54,323: INFO: 320948610: Graph construction completed successfully.]\n"
     ]
    }
   ],
   "source": [
    "# Pipeline Execution\n",
    "\n",
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    graph_construction_config = config.get_graph_construction_config()\n",
    "    graph_constructor = GraphConstructor(config=graph_construction_config)\n",
    "    data = graph_constructor.construct_graph()  # Change this line\n",
    "\n",
    "    if data is not None:\n",
    "        logger.info(\"Graph construction completed successfully.\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.exception(\"An error occurred during graph construction.\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import networkx as nx\n",
    "# import matplotlib.pyplot as plt\n",
    "# import pandas as pd\n",
    "# import random\n",
    "# import logging\n",
    "\n",
    "# def visualize_fraud_subgraph(graph_data_path, transformed_data_path, num_transactions=500, fraud_ratio=0.1):\n",
    "#     \"\"\"\n",
    "#     Visualizes a subgraph containing customers, merchants, and transactions,\n",
    "#     ensuring ~10% fraudulent transactions.\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         # Load graph data\n",
    "#         data = torch.load(graph_data_path)\n",
    "#         df = pd.read_csv(transformed_data_path)\n",
    "        \n",
    "#         # Identify fraud and non-fraud transactions\n",
    "#         fraud_transactions = df[df['is_fraud'] == 1]['transaction_node'].tolist()\n",
    "#         non_fraud_transactions = df[df['is_fraud'] == 0]['transaction_node'].tolist()\n",
    "        \n",
    "#         # Determine how many fraud transactions to include\n",
    "#         num_fraud = min(len(fraud_transactions), int(num_transactions * fraud_ratio))\n",
    "#         num_non_fraud = min(len(non_fraud_transactions), num_transactions - num_fraud)\n",
    "        \n",
    "#         # Select transactions\n",
    "#         selected_fraud = random.sample(fraud_transactions, num_fraud)\n",
    "#         selected_non_fraud = random.sample(non_fraud_transactions, num_non_fraud)\n",
    "#         selected_transactions = set(selected_fraud + selected_non_fraud)\n",
    "        \n",
    "#         # Extract relevant edges\n",
    "#         edges = []\n",
    "#         card_to_transaction = data[\"card\", \"transacts\", \"transaction\"].edge_index.numpy()\n",
    "#         transaction_to_merchant = data[\"transaction\", \"occurs_at\", \"merchant\"].edge_index.numpy()\n",
    "        \n",
    "#         # Filter edges that involve selected transactions\n",
    "#         for src, dst in zip(*card_to_transaction):\n",
    "#             if dst in selected_transactions:\n",
    "#                 edges.append((src, dst))\n",
    "        \n",
    "#         for src, dst in zip(*transaction_to_merchant):\n",
    "#             if src in selected_transactions:\n",
    "#                 edges.append((src, dst))\n",
    "        \n",
    "#         # Create the graph\n",
    "#         G = nx.DiGraph()\n",
    "#         G.add_edges_from(edges)\n",
    "        \n",
    "#         # Node types and sizes\n",
    "#         node_colors = {}\n",
    "#         node_sizes = {}\n",
    "#         for node in G.nodes:\n",
    "#             if node in df['card_node'].values:\n",
    "#                 node_colors[node] = 'skyblue'  # Customers (Cards)\n",
    "#                 node_sizes[node] = 800  # Large\n",
    "#             elif node in df['merchant_node'].values:\n",
    "#                 node_colors[node] = 'lightgreen'  # Merchants\n",
    "#                 node_sizes[node] = 800  # Large\n",
    "#             elif node in selected_transactions:\n",
    "#                 node_colors[node] = 'red' if node in selected_fraud else 'orange'  # Transactions\n",
    "#                 node_sizes[node] = 400  # Smaller\n",
    "        \n",
    "#         # Edge colors (fraud vs non-fraud)\n",
    "#         edge_colors = ['red' if dst in selected_fraud else 'black' for src, dst in edges]\n",
    "        \n",
    "#         # Graph layout\n",
    "#         pos = nx.spring_layout(G, k=0.3, iterations=50)\n",
    "        \n",
    "#         # Draw graph\n",
    "#         plt.figure(figsize=(14, 10))\n",
    "#         nx.draw(\n",
    "#             G, pos, with_labels=True,\n",
    "#             node_color=[node_colors[n] for n in G.nodes],\n",
    "#             node_size=[node_sizes[n] for n in G.nodes],\n",
    "#             edge_color=edge_colors, width=1.5,\n",
    "#             font_size=8, arrows=True\n",
    "#         )\n",
    "        \n",
    "#         # Legend\n",
    "#         legend_labels = {\n",
    "#             'skyblue': 'Customers',\n",
    "#             'lightgreen': 'Merchants',\n",
    "#             'orange': 'Non-Fraud Transactions',\n",
    "#             'red': 'Fraud Transactions',\n",
    "#             'black': 'Non-Fraud Edges',\n",
    "#             'red': 'Fraud Edges'\n",
    "#         }\n",
    "#         legend_patches = [plt.Line2D([0], [0], marker='o', color='w', label=label,\n",
    "#                                       markersize=10, markerfacecolor=color) for color, label in legend_labels.items()]\n",
    "#         plt.legend(handles=legend_patches, loc=\"upper left\")\n",
    "#         plt.title(\"Fraudulent and Non-Fraudulent Transactions Subgraph\")\n",
    "#         plt.show()\n",
    "    \n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"Error visualizing graph: {e}\")\n",
    "\n",
    "# # Example usage\n",
    "# graph_data_path = 'artifacts/graph_construction/graph_data.pt'\n",
    "# transformed_data_path = 'artifacts/graph_construction/node_mapped_data.csv'\n",
    "# visualize_fraud_subgraph(graph_data_path, transformed_data_path, num_transactions=3, fraud_ratio=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import networkx as nx\n",
    "# import matplotlib.pyplot as plt\n",
    "# import pandas as pd\n",
    "# import random\n",
    "# import logging\n",
    "\n",
    "# def visualize_fraud_subgraph(graph_data_path, transformed_data_path, num_transactions=500, fraud_ratio=0.1):\n",
    "#     \"\"\"\n",
    "#     Visualizes a subgraph containing customers, merchants, and transactions,\n",
    "#     ensuring ~10% fraudulent transactions.\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         # Load graph data\n",
    "#         data = torch.load(graph_data_path)\n",
    "#         df = pd.read_csv(transformed_data_path)\n",
    "\n",
    "#         # Identify fraud and non-fraud transactions\n",
    "#         fraud_transactions = df[df['is_fraud'] == 1]['transaction_node'].tolist()\n",
    "#         non_fraud_transactions = df[df['is_fraud'] == 0]['transaction_node'].tolist()\n",
    "\n",
    "#         # Determine how many fraud transactions to include\n",
    "#         num_fraud = min(len(fraud_transactions), int(num_transactions * fraud_ratio))\n",
    "#         num_non_fraud = min(len(non_fraud_transactions), num_transactions - num_fraud)\n",
    "\n",
    "#         # Select transactions\n",
    "#         selected_fraud = random.sample(fraud_transactions, num_fraud)\n",
    "#         selected_non_fraud = random.sample(non_fraud_transactions, num_non_fraud)\n",
    "#         selected_transactions = set(selected_fraud + selected_non_fraud)\n",
    "\n",
    "#         print(f\"Selected Fraud Transactions: {selected_fraud}\")\n",
    "#         print(f\"Selected Non-Fraud Transactions: {selected_non_fraud}\")\n",
    "\n",
    "#         # Extract relevant edges\n",
    "#         edges = []\n",
    "#         card_to_transaction = data[\"card\", \"transacts\", \"transaction\"].edge_index.numpy()\n",
    "#         transaction_to_merchant = data[\"transaction\", \"occurs_at\", \"merchant\"].edge_index.numpy()\n",
    "\n",
    "#         # Get node IDs for card, transaction, and merchant\n",
    "#         card_n_ids = data[\"card\"].n_id.numpy()\n",
    "#         transaction_n_ids = data[\"transaction\"].n_id.numpy()\n",
    "#         merchant_n_ids = data[\"merchant\"].n_id.numpy()\n",
    "\n",
    "#         # Create a mapping from transaction_node in df to transaction_n_ids\n",
    "#         transaction_map = dict(zip(df['transaction_node'], range(len(transaction_n_ids))))\n",
    "\n",
    "#         # Filter edges that involve selected transactions\n",
    "#         for src, dst in zip(*card_to_transaction):\n",
    "#             if transaction_n_ids[dst] in [transaction_n_ids[transaction_map[t]] for t in selected_transactions]:\n",
    "#                 edges.append((card_n_ids[src], transaction_n_ids[dst]))\n",
    "\n",
    "#         for src, dst in zip(*transaction_to_merchant):\n",
    "#             if transaction_n_ids[src] in [transaction_n_ids[transaction_map[t]] for t in selected_transactions]:\n",
    "#                 edges.append((transaction_n_ids[src], merchant_n_ids[dst]))\n",
    "\n",
    "#         print(f\"Edges: {edges}\")\n",
    "\n",
    "#         # Create the graph\n",
    "#         G = nx.DiGraph()\n",
    "#         G.add_edges_from(edges)\n",
    "\n",
    "#         # Node types and sizes\n",
    "#         node_colors = {}\n",
    "#         node_sizes = {}\n",
    "\n",
    "#         # Get card and merchant node IDs from node_stores\n",
    "#         card_nodes = set(card_n_ids)\n",
    "#         merchant_nodes = set(merchant_n_ids)\n",
    "\n",
    "#         print(f\"Card Nodes: {card_nodes}\")\n",
    "#         print(f\"Merchant Nodes: {merchant_nodes}\")\n",
    "\n",
    "#         for node in G.nodes:\n",
    "#             if node in card_nodes:\n",
    "#                 node_colors[node] = 'skyblue'  # Customers (Cards)\n",
    "#                 node_sizes[node] = 800  # Large\n",
    "#             elif node in merchant_nodes:\n",
    "#                 node_colors[node] = 'lightgreen'  # Merchants\n",
    "#                 node_sizes[node] = 800  # Large\n",
    "#             elif node in transaction_n_ids:\n",
    "#                 if df[df['transaction_node'] == list(transaction_map.keys())[list(transaction_map.values()).index(list(transaction_n_ids).index(node))]['is_fraud'].values[0] == 1]:\n",
    "#                     node_colors[node] = 'red'\n",
    "#                 else:\n",
    "#                     node_colors[node] = 'orange'\n",
    "#                 node_sizes[node] = 400\n",
    "\n",
    "#         # Edge colors (fraud vs non-fraud)\n",
    "#         edge_colors = []\n",
    "#         for src, dst in edges:\n",
    "#             if dst in transaction_n_ids:\n",
    "#                 if df[df['transaction_node'] == list(transaction_map.keys())[list(transaction_map.values()).index(list(transaction_n_ids).index(dst))]['is_fraud'].values[0] == 1]:\n",
    "#                     edge_colors.append('red')\n",
    "#                 else:\n",
    "#                     edge_colors.append('black')\n",
    "\n",
    "#         print(f\"Edge Colors: {edge_colors}\")\n",
    "\n",
    "#         # Graph layout\n",
    "#         pos = nx.spring_layout(G, k=0.3, iterations=50)\n",
    "\n",
    "#         # Draw graph\n",
    "#         plt.figure(figsize=(14, 10))\n",
    "#         nx.draw(\n",
    "#             G, pos, with_labels=True,\n",
    "#             node_color=[node_colors[n] for n in G.nodes],\n",
    "#             node_size=[node_sizes[n] for n in G.nodes],\n",
    "#             edge_color=edge_colors, width=1.5,\n",
    "#             font_size=8, arrows=True\n",
    "#         )\n",
    "\n",
    "#         # Legend\n",
    "#         legend_labels = {\n",
    "#             'skyblue': 'Customers',\n",
    "#             'lightgreen': 'Merchants',\n",
    "#             'orange': 'Non-Fraud Transactions',\n",
    "#             'red': 'Fraud Transactions',\n",
    "#             'black': 'Non-Fraud Edges',\n",
    "#             'red': 'Fraud Edges'\n",
    "#         }\n",
    "#         legend_patches = [plt.Line2D([0], [0], marker='o', color='w', label=label,\n",
    "#                                     markersize=10, markerfacecolor=color) for color, label in legend_labels.items()]\n",
    "#         plt.legend(handles=legend_patches, loc=\"upper left\")\n",
    "#         plt.title(\"Fraudulent and Non-Fraudulent Transactions Subgraph\")\n",
    "#         plt.show()\n",
    "\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"Error visualizing graph: {e}\")\n",
    "\n",
    "# # Example usage\n",
    "# graph_data_path = 'artifacts/graph_construction/graph_data.pt'\n",
    "# transformed_data_path = 'artifacts/graph_construction/node_mapped_data.csv'\n",
    "# visualize_fraud_subgraph(graph_data_path, transformed_data_path, num_transactions=10, fraud_ratio=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import networkx as nx\n",
    "# import matplotlib.pyplot as plt\n",
    "# import pandas as pd\n",
    "# import logging\n",
    "# import numpy as np\n",
    "\n",
    "# def visualize_fraud_subgraph_small(graph_data_path, transformed_data_path, num_fraud=1, neighborhood_depth=1):\n",
    "#     \"\"\"\n",
    "#     Visualizes a small subgraph with all arrows pointing to fraudulent transactions in red, excluding self-loops.\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         data = torch.load(graph_data_path)\n",
    "#         df = pd.read_csv(transformed_data_path)\n",
    "\n",
    "#         fraud_transactions = df[df['is_fraud'] == 1]['transaction_node'].tolist()\n",
    "#         selected_fraud = random.sample(fraud_transactions, min(num_fraud, len(fraud_transactions)))\n",
    "\n",
    "#         edges = []\n",
    "#         card_to_transaction = data[\"card\", \"transacts\", \"transaction\"].edge_index.numpy()\n",
    "#         transaction_to_merchant = data[\"transaction\", \"occurs_at\", \"merchant\"].edge_index.numpy()\n",
    "\n",
    "#         card_n_ids = data[\"card\"].n_id.numpy()\n",
    "#         transaction_n_ids = data[\"transaction\"].n_id.numpy()\n",
    "#         merchant_n_ids = data[\"merchant\"].n_id.numpy()\n",
    "\n",
    "#         transaction_map = dict(zip(transaction_n_ids, df['transaction_node']))\n",
    "\n",
    "#         selected_nodes = set()\n",
    "#         for transaction_node_id in selected_fraud:\n",
    "#             transaction_graph_id = list(transaction_map.keys())[list(transaction_map.values()).index(transaction_node_id)]\n",
    "#             selected_nodes.add(transaction_graph_id)\n",
    "\n",
    "#             def expand_neighborhood(node_id, depth):\n",
    "#                 if depth == 0:\n",
    "#                     return\n",
    "#                 for src, dst in zip(*card_to_transaction):\n",
    "#                     if transaction_n_ids[dst] == node_id:\n",
    "#                         selected_nodes.add(card_n_ids[src])\n",
    "#                         selected_nodes.add(transaction_n_ids[dst])\n",
    "#                         expand_neighborhood(card_n_ids[src], depth - 1)\n",
    "#                 for src, dst in zip(*transaction_to_merchant):\n",
    "#                     if transaction_n_ids[src] == node_id:\n",
    "#                         selected_nodes.add(merchant_n_ids[dst])\n",
    "#                         selected_nodes.add(transaction_n_ids[src])\n",
    "#                         expand_neighborhood(merchant_n_ids[dst], depth - 1)\n",
    "\n",
    "#             expand_neighborhood(transaction_graph_id, neighborhood_depth)\n",
    "\n",
    "#         for src, dst in zip(*card_to_transaction):\n",
    "#             if card_n_ids[src] in selected_nodes and transaction_n_ids[dst] in selected_nodes:\n",
    "#                 edges.append((card_n_ids[src], transaction_n_ids[dst]))\n",
    "#         for src, dst in zip(*transaction_to_merchant):\n",
    "#             if transaction_n_ids[src] in selected_nodes and merchant_n_ids[dst] in selected_nodes:\n",
    "#                 edges.append((transaction_n_ids[src], merchant_n_ids[dst]))\n",
    "\n",
    "#         G = nx.DiGraph()\n",
    "#         G.add_edges_from([(src, dst) for src, dst in edges if src != dst])  # Exclude self-loops\n",
    "\n",
    "#         node_colors = {}\n",
    "#         node_sizes = {}\n",
    "#         card_nodes = set(card_n_ids)\n",
    "#         merchant_nodes = set(merchant_n_ids)\n",
    "\n",
    "#         for node in G.nodes:\n",
    "#             if node in card_nodes:\n",
    "#                 node_colors[node] = 'skyblue'\n",
    "#                 node_sizes[node] = 800\n",
    "#             elif node in merchant_nodes:\n",
    "#                 node_colors[node] = 'lightgreen'\n",
    "#                 node_sizes[node] = 800\n",
    "#             elif node in transaction_n_ids:\n",
    "#                 transaction_node_id = transaction_map[node]\n",
    "#                 is_fraud = df[df['transaction_node'] == transaction_node_id]['is_fraud'].values[0]\n",
    "#                 if is_fraud == 1:\n",
    "#                     node_colors[node] = 'red'\n",
    "#                     node_sizes[node] = 400\n",
    "#                 else:\n",
    "#                     node_colors[node] = 'lightcoral'\n",
    "#                     node_sizes[node] = 400\n",
    "\n",
    "#         for src, dst in G.edges():\n",
    "#             if dst in G.nodes():\n",
    "#                 if node_colors.get(dst) != 'red':\n",
    "#                     node_colors[dst] = 'lightgreen'\n",
    "\n",
    "#         fraudulent_node_ids = [node for node, color in node_colors.items() if color == 'red']\n",
    "#         edge_colors = ['red' if dst in fraudulent_node_ids or src in fraudulent_node_ids else 'black' for src, dst in G.edges()]\n",
    "\n",
    "#         # Debugging output\n",
    "#         print(\"Fraudulent Node IDs:\", fraudulent_node_ids)\n",
    "#         print(\"Edges:\", G.edges())\n",
    "#         print(\"Node Colors:\", node_colors)\n",
    "#         print(\"Edge Colors:\", edge_colors)\n",
    "\n",
    "#         # Plotting code\n",
    "#         plt.figure(figsize=(8, 6))\n",
    "#         pos = nx.spring_layout(G)\n",
    "#         nx.draw(G, pos, with_labels=True, node_color=[node_colors[node] for node in G.nodes],\n",
    "#                 node_size=[node_sizes[node] for node in G.nodes], font_size=8, font_color='black', arrows=True,\n",
    "#                 edge_color=edge_colors)\n",
    "\n",
    "#         legend_elements = [plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='skyblue', markersize=10, label='Customers'),\n",
    "#                            plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='lightgreen', markersize=10, label='Receivers'),\n",
    "#                            plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='red', markersize=10, label='Fraud Transactions'),\n",
    "#                            plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='lightcoral', markersize=10, label='Non-Fraud Transactions')]\n",
    "#         plt.legend(handles=legend_elements)\n",
    "\n",
    "#         plt.title(\"Small Fraudulent Transaction Subgraph\")\n",
    "#         plt.show()\n",
    "\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"Error visualizing graph: {e}\")\n",
    "\n",
    "# graph_data_path = 'artifacts/graph_construction/graph_data.pt'\n",
    "# transformed_data_path = 'artifacts/graph_construction/node_mapped_data.csv'\n",
    "# visualize_fraud_subgraph_small(graph_data_path, transformed_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import networkx as nx\n",
    "# import matplotlib.pyplot as plt\n",
    "# import pandas as pd\n",
    "# import logging\n",
    "# import numpy as np\n",
    "\n",
    "# def visualize_fraud_subgraph_small(graph_data_path, transformed_data_path, num_fraud=2, neighborhood_depth=5):\n",
    "#     \"\"\"\n",
    "#     Visualizes a small subgraph with all arrows pointing to fraudulent transactions in red, excluding self-loops, with an expanded neighborhood and improved visualization.\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         data = torch.load(graph_data_path)\n",
    "#         df = pd.read_csv(transformed_data_path)\n",
    "\n",
    "#         fraud_transactions = df[df['is_fraud'] == 1]['transaction_node'].tolist()\n",
    "#         selected_fraud = random.sample(fraud_transactions, min(num_fraud, len(fraud_transactions)))\n",
    "\n",
    "#         edges = []\n",
    "#         card_to_transaction = data[\"card\", \"transacts\", \"transaction\"].edge_index.numpy()\n",
    "#         transaction_to_merchant = data[\"transaction\", \"occurs_at\", \"merchant\"].edge_index.numpy()\n",
    "\n",
    "#         card_n_ids = data[\"card\"].n_id.numpy()\n",
    "#         transaction_n_ids = data[\"transaction\"].n_id.numpy()\n",
    "#         merchant_n_ids = data[\"merchant\"].n_id.numpy()\n",
    "\n",
    "#         transaction_map = dict(zip(transaction_n_ids, df['transaction_node']))\n",
    "\n",
    "#         selected_nodes = set()\n",
    "#         for transaction_node_id in selected_fraud:\n",
    "#             transaction_graph_id = list(transaction_map.keys())[list(transaction_map.values()).index(transaction_node_id)]\n",
    "#             selected_nodes.add(transaction_graph_id)\n",
    "\n",
    "#             def expand_neighborhood(node_id, depth):\n",
    "#                 if depth == 0:\n",
    "#                     return\n",
    "#                 for src, dst in zip(*card_to_transaction):\n",
    "#                     if transaction_n_ids[dst] == node_id:\n",
    "#                         selected_nodes.add(card_n_ids[src])\n",
    "#                         selected_nodes.add(transaction_n_ids[dst])\n",
    "#                         expand_neighborhood(card_n_ids[src], depth - 1)\n",
    "#                 for src, dst in zip(*transaction_to_merchant):\n",
    "#                     if transaction_n_ids[src] == node_id:\n",
    "#                         selected_nodes.add(merchant_n_ids[dst])\n",
    "#                         selected_nodes.add(transaction_n_ids[src])\n",
    "#                         expand_neighborhood(merchant_n_ids[dst], depth - 1)\n",
    "\n",
    "#             expand_neighborhood(transaction_graph_id, neighborhood_depth)\n",
    "\n",
    "#         for src, dst in zip(*card_to_transaction):\n",
    "#             if card_n_ids[src] in selected_nodes and transaction_n_ids[dst] in selected_nodes:\n",
    "#                 edges.append((card_n_ids[src], transaction_n_ids[dst]))\n",
    "#         for src, dst in zip(*transaction_to_merchant):\n",
    "#             if transaction_n_ids[src] in selected_nodes and merchant_n_ids[dst] in selected_nodes:\n",
    "#                 edges.append((transaction_n_ids[src], merchant_n_ids[dst]))\n",
    "\n",
    "#         G = nx.DiGraph()\n",
    "#         G.add_edges_from([(src, dst) for src, dst in edges if src != dst])\n",
    "\n",
    "#         node_colors = {}\n",
    "#         node_sizes = {}\n",
    "#         card_nodes = set(card_n_ids)\n",
    "#         merchant_nodes = set(merchant_n_ids)\n",
    "\n",
    "#         for node in G.nodes:\n",
    "#             if node in card_nodes:\n",
    "#                 node_colors[node] = 'skyblue'\n",
    "#                 node_sizes[node] = 400  # Reduced node size\n",
    "#             elif node in merchant_nodes:\n",
    "#                 node_colors[node] = 'lightgreen'\n",
    "#                 node_sizes[node] = 400  # Reduced node size\n",
    "#             elif node in transaction_n_ids:\n",
    "#                 transaction_node_id = transaction_map[node]\n",
    "#                 is_fraud = df[df['transaction_node'] == transaction_node_id]['is_fraud'].values[0]\n",
    "#                 if is_fraud == 1:\n",
    "#                     node_colors[node] = 'red'\n",
    "#                     node_sizes[node] = 200  # Reduced node size\n",
    "#                 else:\n",
    "#                     node_colors[node] = 'lightcoral'\n",
    "#                     node_sizes[node] = 200  # Reduced node size\n",
    "\n",
    "#         for src, dst in G.edges():\n",
    "#             if dst in G.nodes():\n",
    "#                 if node_colors.get(dst) != 'red':\n",
    "#                     node_colors[dst] = 'lightgreen'\n",
    "\n",
    "#         fraudulent_node_ids = [node for node, color in node_colors.items() if color == 'red']\n",
    "#         edge_colors = ['red' if dst in fraudulent_node_ids or src in fraudulent_node_ids else 'black' for src, dst in G.edges()]\n",
    "\n",
    "#         # Debugging output\n",
    "#         print(\"Fraudulent Node IDs:\", fraudulent_node_ids)\n",
    "#         print(\"Edges:\", G.edges())\n",
    "#         print(\"Node Colors:\", node_colors)\n",
    "#         print(\"Edge Colors:\", edge_colors)\n",
    "\n",
    "#         # Plotting code\n",
    "#         plt.figure(figsize=(18, 12))  # Increased figure size\n",
    "#         pos = nx.kamada_kawai_layout(G)  # Use kamada_kawai_layout\n",
    "#         nx.draw(G, pos, with_labels=False, node_color=[node_colors[node] for node in G.nodes],\n",
    "#                 node_size=[node_sizes[node] for node in G.nodes], font_size=8, font_color='black', arrows=True,\n",
    "#                 edge_color=edge_colors, width=0.5)  # Reduced edge width\n",
    "\n",
    "#         # Label only a subset of nodes\n",
    "#         labels = {node: node for node in G.nodes if node in fraudulent_node_ids or node in list(G.neighbors(fraudulent_node_ids[0]))}\n",
    "#         nx.draw_networkx_labels(G, pos, labels=labels, font_size=8)\n",
    "\n",
    "#         legend_elements = [plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='skyblue', markersize=10, label='Customers'),\n",
    "#                            plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='lightgreen', markersize=10, label='Receivers'),\n",
    "#                            plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='red', markersize=10, label='Fraud Transactions'),\n",
    "#                            plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='lightcoral', markersize=10, label='Non-Fraud Transactions')]\n",
    "#         plt.legend(handles=legend_elements)\n",
    "\n",
    "#         plt.title(\"Expanded Fraudulent Transaction Subgraph (Improved Visualization)\")\n",
    "#         plt.show()\n",
    "\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"Error visualizing graph: {e}\")\n",
    "\n",
    "# graph_data_path = 'artifacts/graph_construction/graph_data.pt'\n",
    "# transformed_data_path = 'artifacts/graph_construction/node_mapped_data.csv'\n",
    "# visualize_fraud_subgraph_small(graph_data_path, transformed_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
