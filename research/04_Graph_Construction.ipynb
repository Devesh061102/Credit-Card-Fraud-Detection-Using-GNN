{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GNN for fraud detection:\n",
    "Creating a multigraph for fraud detection using transaction data and applying a Graph Neural Network (GNN) on the edge list can be done in the following steps:\n",
    "\n",
    "1. Prepare the transaction data: Collect and organize the transaction data into a format that can be used to create the edges of the multigraph. For example, each transaction could be represented as a tuple (node1, node2, attributes), where node1 and node2 represent the sender and receiver of the transaction, and attributes is a dictionary containing properties such as the amount, timestamp, and transaction type.\n",
    "\n",
    "2. Create the multigraph: Use the transaction data to create a multigraph using the NetworkX library. The add_edge() method can be used to add edges to the multigraph, where each edge represents a transaction.\n",
    "\n",
    "3. Extract the edges list and their features: Use the edges() method of the multigraph to extract the edges list and their features, which will be used as input to the GNN.\n",
    "\n",
    "4. Apply a GNN on the edge list: Use a GNN library such as PyTorch Geometric, Deep Graph Library (DGL) or Spektral to apply a GNN on the edge list. The GNN will learn representations of the edges in the multigraph and use them to classify the edges as fraudulent or non-fraudulent.\n",
    "\n",
    "5. Evaluation: To evaluate the performance of the GNN, you can split the data into train and test sets, and use the test set to evaluate the accuracy, precision, recall, and F1-score of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Final-Year-Project\\\\Credit-Card-Fraud-Detection-Using-GNN'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entity\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class GraphConstructionConfig:\n",
    "    root_dir: Path\n",
    "    transformed_data_path: Path\n",
    "    graph_data_path: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Credit_Card_Fraud_Detection.constants import *\n",
    "from Credit_Card_Fraud_Detection.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath=CONFIG_FILE_PATH,\n",
    "        params_filepath=PARAMS_FILE_PATH,\n",
    "        schema_filepath=SCHEMA_FILE_PATH\n",
    "    ):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_graph_construction_config(self) -> GraphConstructionConfig:\n",
    "        print(\"get_graph_construction_config method called\") # add this line\n",
    "        config = self.config.graph_construction\n",
    "        create_directories([config.root_dir])\n",
    "        \n",
    "        graph_construction_config = GraphConstructionConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            transformed_data_path=config.transformed_data_path,\n",
    "            graph_data_path=config.graph_data_path,\n",
    "        )\n",
    "        return graph_construction_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "from Credit_Card_Fraud_Detection import logger\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GraphConstructor:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "\n",
    "    def create_node_ids(self, df):\n",
    "        \"\"\"\n",
    "        Directly uses existing customer_id, merchant_id, and transaction_unique as node IDs.\n",
    "        Removes the original columns after creating node IDs.\n",
    "        \"\"\"\n",
    "        df[\"transaction_node\"] = df[\"transaction_unique\"].astype(int)\n",
    "        df[\"customer_node\"] = df[\"customer_id\"].astype(int)\n",
    "        df[\"merchant_node\"] = df[\"merchant_id\"].astype(int)\n",
    "\n",
    "        df.drop(columns=[\"customer_id\", \"merchant_id\", \"transaction_unique\"], inplace=True)  # Remove old columns\n",
    "\n",
    "        logger.info(f\"New max transaction_node in df: {df['transaction_node'].max()}\")\n",
    "        logger.info(f\"Total transaction nodes: {len(df['transaction_node'].unique())}\")\n",
    "        logger.info(\"Node indices created successfully.\")\n",
    "\n",
    "        return df\n",
    "\n",
    "    def create_edge_indices(self, df):\n",
    "        customer_to_transaction_edges = torch.tensor(df[[\"customer_node\", \"transaction_node\"]].values.T, dtype=torch.long)\n",
    "        transaction_to_merchant_edges = torch.tensor(df[[\"transaction_node\", \"merchant_node\"]].values.T, dtype=torch.long)\n",
    "\n",
    "        logger.info(f\"Customer-to-Transaction edges shape: {customer_to_transaction_edges.shape}\")\n",
    "        logger.info(f\"Transaction-to-Merchant edges shape: {transaction_to_merchant_edges.shape}\")\n",
    "\n",
    "        return customer_to_transaction_edges, transaction_to_merchant_edges\n",
    "\n",
    "    def create_node_features(self, df):\n",
    "        customer_features_list = [\"customer_avg_amt\", \"customer_min_amt\", \"customer_amt_std\"]\n",
    "        merchant_features_list = [\"merchant_avg_amt\", \"merchant_min_amt\", \"merchant_amt_std\"]\n",
    "        transaction_features_list = [\n",
    "            \"high_amt\", \"amt_ratio_merchant\", \"sqrt_amt\", \"amt\", \"amt_diff_customer_avg\",\n",
    "            \"hour_cos\", \"amt_per_city_pop\", \"merchant_category_fraud_risk\"\n",
    "        ]\n",
    "\n",
    "        customer_features_dim = len(customer_features_list)\n",
    "        merchant_features_dim = len(merchant_features_list)\n",
    "        transaction_features_dim = len(transaction_features_list)\n",
    "\n",
    "        unique_customer_nodes = df[\"customer_node\"].unique()\n",
    "        unique_merchant_nodes = df[\"merchant_node\"].unique()\n",
    "\n",
    "        customer_features = torch.zeros((len(unique_customer_nodes), customer_features_dim), dtype=torch.float32)\n",
    "        merchant_features = torch.zeros((len(unique_merchant_nodes), merchant_features_dim), dtype=torch.float32)\n",
    "        transaction_features = torch.tensor(df[transaction_features_list].values, dtype=torch.float32)\n",
    "\n",
    "        for i, customer_id in enumerate(unique_customer_nodes):\n",
    "            group = df[df[\"customer_node\"] == customer_id]\n",
    "            customer_features[i] = torch.tensor(group[customer_features_list].mean().values, dtype=torch.float32)\n",
    "\n",
    "        for i, merchant_id in enumerate(unique_merchant_nodes):\n",
    "            group = df[df[\"merchant_node\"] == merchant_id]\n",
    "            merchant_features[i] = torch.tensor(group[merchant_features_list].mean().values, dtype=torch.float32)\n",
    "\n",
    "        logger.info(\"Node features created correctly.\")\n",
    "\n",
    "        # Debugging: Check for NaN and Inf\n",
    "        if torch.isnan(customer_features).any() or torch.isinf(customer_features).any():\n",
    "            logger.error(\"NaN or Inf values found in customer_features.\")\n",
    "        if torch.isnan(merchant_features).any() or torch.isinf(merchant_features).any():\n",
    "            logger.error(\"NaN or Inf values found in merchant_features.\")\n",
    "        if torch.isnan(transaction_features).any() or torch.isinf(transaction_features).any():\n",
    "            logger.error(\"NaN or Inf values found in transaction_features.\")\n",
    "\n",
    "        return customer_features, merchant_features, transaction_features\n",
    "\n",
    "    def create_transaction_labels(self, df):\n",
    "        \"\"\"Creates labels only for unique transaction nodes.\"\"\"\n",
    "        transaction_labels = {}\n",
    "        for transaction_id, group in df.groupby(\"transaction_node\"):  # change to transaction_node\n",
    "            transaction_labels[transaction_id] = group[\"is_fraud\"].iloc[0]\n",
    "\n",
    "        y = torch.tensor(list(transaction_labels.values()), dtype=torch.float32).view(-1, 1)\n",
    "        return y\n",
    "\n",
    "    def train_test_split_nodes(self, y):\n",
    "        num_transaction_nodes = len(y)\n",
    "        train_indices, test_indices = train_test_split(\n",
    "            torch.arange(num_transaction_nodes),\n",
    "            test_size=0.2,\n",
    "            random_state=42,\n",
    "            stratify=y.squeeze().numpy()\n",
    "        )\n",
    "\n",
    "        transaction_train_mask = torch.zeros(num_transaction_nodes, dtype=torch.bool)\n",
    "        transaction_test_mask = torch.zeros(num_transaction_nodes, dtype=torch.bool)\n",
    "\n",
    "        transaction_train_mask[train_indices] = True\n",
    "        transaction_test_mask[test_indices] = True\n",
    "\n",
    "        logger.info(\"Train-test split applied.\")\n",
    "\n",
    "        return transaction_train_mask, transaction_test_mask\n",
    "\n",
    "    def describe_data_structure(self, data, filepath):\n",
    "        with open(filepath, 'w') as f:\n",
    "            f.write(\"Data Object Structure:\\n\")\n",
    "            for node_type in data.node_types:\n",
    "                f.write(f\"  Node type: {node_type}\\n\")\n",
    "                if hasattr(data[node_type], 'x'):\n",
    "                    f.write(f\"    x: {data[node_type].x.shape}, dtype={data[node_type].x.dtype}\\n\")\n",
    "                if hasattr(data[node_type], 'y'):\n",
    "                    f.write(f\"    y: {data[node_type].y.shape}, dtype={data[node_type].y.dtype}\\n\")\n",
    "                if hasattr(data[node_type], 'train_mask'):\n",
    "                    f.write(f\"    train_mask: {data[node_type].train_mask.shape}, dtype={data[node_type].train_mask.dtype}\\n\")\n",
    "                if hasattr(data[node_type], 'test_mask'):\n",
    "                    f.write(f\"    test_mask: {data[node_type].test_mask.shape}, dtype={data[node_type].test_mask.dtype}\\n\")\n",
    "                if hasattr(data[node_type], 'n_id'):\n",
    "                    f.write(f\"    n_id: {data[node_type].n_id.shape}, dtype={data[node_type].n_id.dtype}\\n\")\n",
    "            for edge_type in data.edge_types:\n",
    "                f.write(f\"  Edge type: {edge_type}\\n\")\n",
    "                f.write(f\"    edge_index: {data[edge_type].edge_index.shape}, dtype={data[edge_type].edge_index.dtype}\\n\")\n",
    "\n",
    "        logger.info(f\"Data structure description saved to: {filepath}\")\n",
    "\n",
    "    def construct_graph(self):\n",
    "        df = pd.read_csv(self.config.transformed_data_path)\n",
    "\n",
    "        df = self.create_node_ids(df)\n",
    "        customer_to_transaction_edges, transaction_to_merchant_edges = self.create_edge_indices(df)\n",
    "        customer_features, merchant_features, transaction_features = self.create_node_features(df)\n",
    "        y = self.create_transaction_labels(df)\n",
    "        transaction_train_mask, transaction_test_mask = self.train_test_split_nodes(y)\n",
    "\n",
    "        data = HeteroData()\n",
    "        data[\"customer\"].x = customer_features\n",
    "        data[\"merchant\"].x = merchant_features\n",
    "        data[\"transaction\"].x = transaction_features\n",
    "        data[\"customer\", \"transacts\", \"transaction\"].edge_index = customer_to_transaction_edges\n",
    "        data[\"transaction\", \"occurs_at\", \"merchant\"].edge_index = transaction_to_merchant_edges\n",
    "        data[\"transaction\", \"transacted_by\", \"customer\"].edge_index = customer_to_transaction_edges.flip(0)\n",
    "        data[\"merchant\", \"related_to\", \"transaction\"].edge_index = transaction_to_merchant_edges.flip(0)\n",
    "        data[\"transaction\"].y = y\n",
    "        data[\"transaction\"].train_mask = transaction_train_mask\n",
    "        data[\"transaction\"].test_mask = transaction_test_mask\n",
    "\n",
    "        # Assign n_id attributes\n",
    "        data[\"customer\"].n_id = torch.tensor(df[\"customer_node\"].unique())\n",
    "        data[\"merchant\"].n_id = torch.tensor(df[\"merchant_node\"].unique())\n",
    "        data[\"transaction\"].n_id = torch.tensor(df[\"transaction_node\"].unique())\n",
    "\n",
    "        # Create merchant node ID mapping\n",
    "        merchant_id_mapping = {merchant_id: idx for idx, merchant_id in enumerate(df[\"merchant_node\"].unique())}\n",
    "\n",
    "        # Adjust merchant edge indices\n",
    "        data[\"transaction\", \"occurs_at\", \"merchant\"].edge_index[1] = torch.tensor([merchant_id_mapping[merchant_id.item()] for merchant_id in data[\"transaction\", \"occurs_at\", \"merchant\"].edge_index[1]])\n",
    "        data[\"merchant\", \"related_to\", \"transaction\"].edge_index[0] = torch.tensor([merchant_id_mapping[merchant_id.item()] for merchant_id in data[\"merchant\", \"related_to\", \"transaction\"].edge_index[0]])\n",
    "\n",
    "\n",
    "        # Debugging: Check edge indices and data types\n",
    "        for edge_type, edge_index in data.edge_index_dict.items():\n",
    "            src_node_type, _, dst_node_type = edge_type\n",
    "            num_src_nodes = data[src_node_type].x.size(0)\n",
    "            num_dst_nodes = data[dst_node_type].x.size(0)\n",
    "\n",
    "            if (edge_index[0] >= num_src_nodes).any() or (edge_index[1] >= num_dst_nodes).any():\n",
    "                logger.error(f\"Edge index out of bounds for edge type {edge_type}\")\n",
    "            if edge_index.dtype != torch.long:\n",
    "                logger.error(f\"Edge index dtype is not torch.long for edge type {edge_type}\")\n",
    "\n",
    "        for node_type in data.node_types:\n",
    "            if data[node_type].x.dtype != torch.float32:\n",
    "                logger.error(f\"{node_type} features dtype is not torch.float32\")\n",
    "\n",
    "        # Debugging: Check min/max node IDs and n_id values\n",
    "        logger.info(f\"Min customer_node: {df['customer_node'].min()}, Max customer_node: {df['customer_node'].max()}\")\n",
    "        logger.info(f\"Min merchant_node: {df['merchant_node'].min()}, Max merchant_node: {df['merchant_node'].max()}\")\n",
    "        logger.info(f\"Min transaction_node: {df['transaction_node'].min()}, Max transaction_node: {df['transaction_node'].max()}\")\n",
    "\n",
    "        logger.info(f\"Customer n_id: {data['customer'].n_id.min()} to {data['customer'].n_id.max()}\")\n",
    "        logger.info(f\"Merchant n_id: {data['merchant'].n_id.min()} to {data['merchant'].n_id.max()}\")\n",
    "        logger.info(f\"Transaction n_id: {data['transaction'].n_id.min()} to {data['transaction'].n_id.max()}\")\n",
    "\n",
    "        # Debugging: Check feature and edge_index shapes\n",
    "        for node_type in data.node_types:\n",
    "            if hasattr(data[node_type], 'x'):\n",
    "                logger.info(f\"{node_type} features shape: {data[node_type].x.shape}\")\n",
    "        for edge_type in data.edge_types:\n",
    "            logger.info(f\"{edge_type} edge_index shape: {data[edge_type].edge_index.shape}\")\n",
    "\n",
    "        torch.save(data, self.config.graph_data_path)\n",
    "        logger.info(f\"Graph data saved to: {self.config.graph_data_path}\")\n",
    "\n",
    "        # Save graph structure description\n",
    "        structure_save_path = os.path.join(self.config.root_dir, \"graph_structure.txt\")\n",
    "        self.describe_data_structure(data, structure_save_path)\n",
    "\n",
    "        # Save updated DataFrame\n",
    "        node_mapped_data_path = os.path.join(self.config.root_dir, \"node_mapped_data.csv\")\n",
    "        df.to_csv(node_mapped_data_path, index=False)\n",
    "        logger.info(f\"Updated data frame saved to: {node_mapped_data_path}\")\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-03-24 09:32:01,495: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-03-24 09:32:01,497: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-03-24 09:32:01,499: INFO: common: yaml file: schema.yaml loaded successfully]\n",
      "[2025-03-24 09:32:01,500: INFO: common: created directory at: artifacts]\n",
      "get_graph_construction_config method called\n",
      "[2025-03-24 09:32:01,502: INFO: common: created directory at: artifacts/graph_construction]\n",
      "[2025-03-24 09:32:02,857: INFO: 2814552714: New max transaction_node in df: 1295933]\n",
      "[2025-03-24 09:32:02,883: INFO: 2814552714: Total transaction nodes: 1295934]\n",
      "[2025-03-24 09:32:02,884: INFO: 2814552714: Node indices created successfully.]\n",
      "[2025-03-24 09:32:02,919: INFO: 2814552714: Customer-to-Transaction edges shape: torch.Size([2, 1295934])]\n",
      "[2025-03-24 09:32:02,919: INFO: 2814552714: Transaction-to-Merchant edges shape: torch.Size([2, 1295934])]\n",
      "[2025-03-24 09:32:06,205: INFO: 2814552714: Node features created correctly.]\n",
      "[2025-03-24 09:32:45,355: INFO: 2814552714: Train-test split applied.]\n",
      "[2025-03-24 09:32:52,509: INFO: 2814552714: Min customer_node: 0, Max customer_node: 907]\n",
      "[2025-03-24 09:32:52,514: INFO: 2814552714: Min merchant_node: 908, Max merchant_node: 1600]\n",
      "[2025-03-24 09:32:52,516: INFO: 2814552714: Min transaction_node: 0, Max transaction_node: 1295933]\n",
      "[2025-03-24 09:32:52,520: INFO: 2814552714: Customer n_id: 0 to 907]\n",
      "[2025-03-24 09:32:52,522: INFO: 2814552714: Merchant n_id: 908 to 1600]\n",
      "[2025-03-24 09:32:52,523: INFO: 2814552714: Transaction n_id: 0 to 1295933]\n",
      "[2025-03-24 09:32:52,523: INFO: 2814552714: customer features shape: torch.Size([908, 3])]\n",
      "[2025-03-24 09:32:52,523: INFO: 2814552714: merchant features shape: torch.Size([693, 3])]\n",
      "[2025-03-24 09:32:52,525: INFO: 2814552714: transaction features shape: torch.Size([1295934, 8])]\n",
      "[2025-03-24 09:32:52,525: INFO: 2814552714: ('customer', 'transacts', 'transaction') edge_index shape: torch.Size([2, 1295934])]\n",
      "[2025-03-24 09:32:52,526: INFO: 2814552714: ('transaction', 'occurs_at', 'merchant') edge_index shape: torch.Size([2, 1295934])]\n",
      "[2025-03-24 09:32:52,526: INFO: 2814552714: ('transaction', 'transacted_by', 'customer') edge_index shape: torch.Size([2, 1295934])]\n",
      "[2025-03-24 09:32:52,527: INFO: 2814552714: ('merchant', 'related_to', 'transaction') edge_index shape: torch.Size([2, 1295934])]\n",
      "[2025-03-24 09:32:52,658: INFO: 2814552714: Graph data saved to: artifacts/graph_construction/graph_data.pt]\n",
      "[2025-03-24 09:32:52,658: INFO: 2814552714: Data structure description saved to: artifacts/graph_construction\\graph_structure.txt]\n",
      "[2025-03-24 09:33:02,808: INFO: 2814552714: Updated data frame saved to: artifacts/graph_construction\\node_mapped_data.csv]\n",
      "[2025-03-24 09:33:02,815: INFO: 320948610: Graph construction completed successfully.]\n"
     ]
    }
   ],
   "source": [
    "# Pipeline Execution\n",
    "\n",
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    graph_construction_config = config.get_graph_construction_config()\n",
    "    graph_constructor = GraphConstructor(config=graph_construction_config)\n",
    "    data = graph_constructor.construct_graph()  # Change this line\n",
    "\n",
    "    if data is not None:\n",
    "        logger.info(\"Graph construction completed successfully.\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.exception(\"An error occurred during graph construction.\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
